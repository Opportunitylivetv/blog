<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.4.3">Jekyll</generator><link href="https://bitworking.org/news/feed/index.atom" rel="self" type="application/atom+xml" /><link href="https://bitworking.org/" rel="alternate" type="text/html" /><updated>2017-07-17T20:28:13-04:00</updated><id>https://bitworking.org/</id><title type="html">BitWorking</title><subtitle>Joe Gregorio - REST, Web, Python, Go, APIs, Dad, Husband, Maker, or any linear combination of such. Googler.
</subtitle><entry><title type="html">Data binding and JS frameworks</title><link href="https://bitworking.org/news/2017/07/data-binding-and-js-frameworks" rel="alternate" type="text/html" title="Data binding and JS frameworks" /><published>2017-07-16T00:00:00-04:00</published><updated>2017-07-16T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/07/data-binding-and-js-frameworks</id><content type="html" xml:base="https://bitworking.org/news/2017/07/data-binding-and-js-frameworks">&lt;p&gt;It was over three years ago that I wrote
&lt;a href=&quot;https://bitworking.org/news/2014/05/zero_framework_manifesto&quot;&gt;No more JS frameworks&lt;/a&gt;, at which time
I was roundly criticized for not understanding that data binding could only be
done via JS framework, the two were inextricably linked, and only 2-way data
binding would do, as one way data binding was for weak-minded fools who
weren’t building real applications. You can find the comments on HN yourself,
I don’t link to that cesspool.&lt;/p&gt;

&lt;p&gt;So, in that context, it was funny to read
&lt;a href=&quot;https://medium.com/@chriscordle/why-angular-2-4-is-too-little-too-late-ea86d7fa0bae&quot;&gt;Why Angular 2/4 Is Too Little, Too Late&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Two way data-binding was a feature in 2013 and Facebook said it was a &lt;strong&gt;bug&lt;/strong&gt;.
It turns out they were &lt;em&gt;right&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The post goes on to explain how the “industry settled on
&lt;a href=&quot;http://redux.js.org/&quot;&gt;Redux&lt;/a&gt;”, which is nice to see that the functionality
is delivered as a standalone library, and &lt;a href=&quot;https://github.com/reactjs/redux/blob/master/LICENSE.md&quot;&gt;MIT Licensed&lt;/a&gt;,
because &lt;a href=&quot;https://issues.apache.org/jira/browse/LEGAL-303&quot;&gt;licenses matter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My only concern is that I believe I too work in the industry and I’ve spent
the last three years delivering applications using
&lt;a href=&quot;https://www.polymer-project.org/&quot;&gt;Polymer&lt;/a&gt;, so I guess I’m not “settled”?&lt;/p&gt;</content><author><name></name></author><summary type="html">It was over three years ago that I wrote No more JS frameworks, at which time I was roundly criticized for not understanding that data binding could only be done via JS framework, the two were inextricably linked, and only 2-way data binding would do, as one way data binding was for weak-minded fools who weren’t building real applications. You can find the comments on HN yourself, I don’t link to that cesspool.</summary></entry><entry><title type="html">Tile Store</title><link href="https://bitworking.org/news/2017/07/tile-store" rel="alternate" type="text/html" title="Tile Store" /><published>2017-07-08T00:00:00-04:00</published><updated>2017-07-08T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/07/tile-store</id><content type="html" xml:base="https://bitworking.org/news/2017/07/tile-store">&lt;p&gt;My team at Google is the infrastructure team for &lt;a href=&quot;https://skia.org&quot;&gt;Skia&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Skia is an open source 2D graphics library which provides common APIs that work
across a variety of hardware and software platforms. It serves as the graphics
engine for Google Chrome and Chrome OS, Android, Mozilla Firefox and Firefox
OS, and many other products.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Skia, being a graphics library, needs to be tested for both performance and
correctness, and being cross-platform, it needs to be tested across a wide
variety of platforms and under different configurations. Skia has a variety of
backends, i.e. the same drawing commands can be directed to be rendered via:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Raster - Using the CPU-only.&lt;/li&gt;
  &lt;li&gt;Ganesh - Skia’s GPU-accelerated backend.&lt;/li&gt;
  &lt;li&gt;PDF - PDF document creation.&lt;/li&gt;
  &lt;li&gt;SVG - An experimental SVG renderer.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of those backends need to be tested across different platforms (Windows,
Android, Linux, Max, iOS), different architectures (x86_64, Arm64, Arm7), and a
wide range of other options that can be selected on how Skia renders. Testing a
wide range of GPUs is required because different GPUs have different behaviors,
including some very buggy but widely deployed versions of OpenGL, so we current
test against a large number of both desktop and mobile GPUs. All of this
variety creates a combinatorial explosion in test data. For every commit to
Skia the tests result in roughly 800,000 performance metrics and one million
images being rendered. There are about 30 commits a day to the Skia repo, so
that ends up being a lot of data. Sure, not a lot compared to other projects in
Google, but Skia is open source, and we prefer to build all of our tooling also
as open source, and we needed to build tools to analyze and monitor all those
performance metrics and correctness images, and so we needed data storage with
the following requirements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Not an SQL database.&lt;/li&gt;
  &lt;li&gt;Very fast access for recent data to allow ad-hoc analysis.&lt;/li&gt;
  &lt;li&gt;Reasonable access for older data.&lt;/li&gt;
  &lt;li&gt;Commit based organization.&lt;/li&gt;
  &lt;li&gt;Robust, i.e. we can’t lose data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The requirement that it not be an SQL database is a personal preference, I’m
sure there are a large contingent of people that will tell me that Postgres is
the perfect solution, but apparently I’m not smart enough to run/use/tune an
SQL database, particularly for large amounts of data. I might give &lt;a href=&quot;https://cloud.google.com/spanner/&quot;&gt;Spanner&lt;/a&gt; a
chance  in the future, and if so I will certainly give an update. &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;BigQuery&lt;/a&gt;
might also work. Regardless, we built these apps a long time before either
Spanner or BigQuery were available, so they weren’t viable options at the time.&lt;/p&gt;

&lt;p&gt;One of the other odd requirements is the commit based organization of the data.
This is obviously because the data needs to align with the commits to Skia, but
it isn’t that straightforward because tests on different machines take
different amounts of time, and we also continually backfill tests when we have
spare capacity, so test results almost never arrive in order.&lt;/p&gt;

&lt;p&gt;Since there wasn’t a single system that could meet all these requirements we
split the problem into two systems, one for robust storage, and a second system
for fast access for real time analysis.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Robust storage (GCS) - The ‘source of truth’ documents are stored in Google Cloud Storage.&lt;/li&gt;
  &lt;li&gt;Fast Access (Tile Store) - An intermediate form, built on key-value stores, such as BoltDB, organized into chunks of commits called tiles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Storing the source of truth documents on Google Cloud Storage takes care of the
robustness. The data files are all JSON and PNG images, which is what is
emitted by the tools that do the performance and correctness testing. The JSON
files are written out to a unique name which include year/month/day/hour in the
path. This allows for easy rebuilding of the Tile Store, just scan for all the
files based on the year/month/day/hour over your desired time range and ingest
them into the Tile Store. And given that the Tile Store can be rebuilt easily
from the ‘source of truth’ documents, we don’t need to back them up.&lt;/p&gt;

&lt;p&gt;The Tile Store is optimized for very fast writes and fast querying.
Additionally, we run on machines large enough to keep all the data for the last
100 commits in memory for very fast access, refreshed from the tiles
periodically.&lt;/p&gt;

&lt;p&gt;For trace data we store each point as a pair, the index of the point and then
the value of the trace at that point. That is, if the tile size is 50 then each
point in a trace is at an index in [0, 49]. So the values stored for a trace
might look like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[0, 1.23], [1, 3.21], [2, 5.67], ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note that the points may not arrive in order, so they could actually be stored
as:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[2, 5.67], [0, 1.23], [1, 3.21], ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Also note that points are only appended, and the last value for a point is the
one that’s used, so duplicate data may exist in the trace:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[2, 5.67], [0, 1.23], [1, 3.21], [2, 5.50], ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This can happen if a test is re-run, we always use the latter value, so the
value at index 2 of this trace will be 5.50, not 5.67.&lt;/p&gt;

&lt;p&gt;You can check out the &lt;a href=&quot;https://godoc.org/go.skia.org/infra/perf/go/ptracestore&quot;&gt;code and documentation&lt;/a&gt; if you are interested in the
details of the how the tiles are structured.&lt;/p&gt;

&lt;p&gt;I wrote this up mostly as a historical marker, since by next year we might be
fully on Spanner or some other storage technology, and also to find out how
other people have solved similar problems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: I just recently came across this talk
&lt;a href=&quot;https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/&quot;&gt;Turning the database inside-out with Apache Samza&lt;/a&gt;,
and realized this is very similar, i.e. we use Google Cloud Storage as our
streaming log, and the Tile Store is our Materialized View.&lt;/p&gt;</content><author><name></name></author><summary type="html">My team at Google is the infrastructure team for Skia:</summary></entry><entry><title type="html">L-Systems</title><link href="https://bitworking.org/news/2017/07/l-systems" rel="alternate" type="text/html" title="L-Systems" /><published>2017-07-02T00:00:00-04:00</published><updated>2017-07-02T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/07/l-systems</id><content type="html" xml:base="https://bitworking.org/news/2017/07/l-systems">&lt;p&gt;
  &lt;a href=&quot;https://en.wikipedia.org/wiki/L-system&quot;&gt;L-Systems&lt;/a&gt; are cool. The amount of complexity, and
  naturalness of the forms you can get from such a tiny amount of code is
  amazing.
&lt;/p&gt;
  &lt;style type=&quot;text/css&quot; media=&quot;screen&quot;&gt;
    canvas {
    }
  &lt;/style&gt;

  &lt;canvas id=canvas width=400 height=600&gt;&lt;/canvas&gt;
  &lt;script id=src type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var a = document.getElementById('canvas');
      var c = a.getContext(&quot;2d&quot;);
      function E(s) { return s ? (rules[s[0]] + E(s.substr(1))) : &quot;&quot; }
      M = Math
      r = M.random
      rules = {
        X: &quot;F-[[X]+X]+F[+FX]-X&quot;,
        F: &quot;FF&quot;,
        &quot;+&quot;: &quot;+&quot;,
        &quot;-&quot;: &quot;-&quot;,
        &quot;[&quot;: &quot;[&quot;,
        &quot;]&quot;: &quot;]&quot;,
      }
      L = E(E(E(E(E(&quot;X&quot;)))))
      ys = []
      function draw(x, y, len) {
        p = { x: x, y: y, a: 3 }
        st = []
        c.beginPath()
        c.moveTo(p.x, p.y)
        L.split(&quot;&quot;).forEach(function(ch) {
          if (ch == &quot;F&quot;) {
            p.x += len*M.sin(p.a)
            p.y += len*M.cos(p.a)
            c.lineTo(p.x, p.y)
            c.stroke()
          } else if (ch == &quot;-&quot;) {
            p.a += r()/2
          } else if (ch == &quot;+&quot;) {
            p.a -= r()/2
          } else if (ch == &quot;[&quot;) {
            st.push(JSON.parse(JSON.stringify(p)))
          } else if (ch == &quot;]&quot;) {
            p = st.pop()
            c.beginPath()
            c.moveTo(p.x, p.y)
          }
        })
      }
      for (i = 0; i &lt; a.height/2; i++) {
        ys.push(1-Math.sin(r()*Math.PI/2));
      }
      ys.sort(function(a, b) {return a-b});
      oneStep = function() {
        var v = ys.shift();
        if (v) {
          cl = 0|(1-v)*255
          c.strokeStyle = &quot;rgb(&quot;+[cl,cl,cl]+&quot;)&quot;
          draw(r()*(a.width+100)-50, v*(a.height+100), v*3+0.1)
        }
        window.setTimeout(oneStep, 1);
      }
      window.setTimeout(oneStep, 1);
    })();
  &lt;/script&gt;
  &lt;p&gt;
    The code is intentionally compact as I was intending to submit something
    along these lines to a &lt;a
      href=&quot;https://en.wikipedia.org/wiki/Code_golf&quot;&gt;code golf&lt;/a&gt;
    competition, but then got distracted.
  &lt;/p&gt;
  &lt;pre&gt;&lt;code id=code&gt;&lt;/code&gt;&lt;/pre&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    document.getElementById('code').textContent = document.getElementById('src').textContent;
  &lt;/script&gt;</content><author><name></name></author><summary type="html">L-Systems are cool. The amount of complexity, and naturalness of the forms you can get from such a tiny amount of code is amazing.</summary></entry><entry><title type="html">Compute and Moore’s Law</title><link href="https://bitworking.org/news/2017/06/compute-and-moores-law" rel="alternate" type="text/html" title="Compute and Moore's Law" /><published>2017-06-21T00:00:00-04:00</published><updated>2017-06-21T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/06/compute-and-moores-law</id><content type="html" xml:base="https://bitworking.org/news/2017/06/compute-and-moores-law">&lt;p&gt;This article from Technology Review,
&lt;a href=&quot;https://www.technologyreview.com/s/607917/how-ai-can-keep-accelerating-after-moores-law/&quot;&gt;How AI Can Keep Accelerating After Moore’s Law&lt;/a&gt;
is a good follow-on from a previous article
&lt;a href=&quot;https://www.technologyreview.com/s/601441/moores-law-is-dead-now-what/&quot;&gt;Moore’s Law Is Dead. Now What?&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the second article:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Engineers have kept GPUs getting more powerful because they can be more
specialized to the particular math they need to perform for graphics or
machine learning, he says.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In order to continue to squeeze more performance out of the same number of
transistors and/or watts, we are going to need to get closer to the metal, and
the metal is going to have to become more and more specialized, or at the very
least, the metal has to stop looking like monolithic CPUs with a small number
of cores.&lt;/p&gt;

&lt;p&gt;GPUs by themselves, even if you only have OpenGL, are attractive because
of the enormous amount of specialized computational power available. This power is what
originally attracted people to General Purpose GPU
&lt;a href=&quot;https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units&quot;&gt;GPGPU&lt;/a&gt;, which started as
people transforming scientific computations into a graphical form to get them
to run on a GPU. That work in turn drove the creation and adoption of general
compute APIs like CUDA and then OpenCL, which expose the underlying compute
units and specialized memory access features in a GPU.&lt;/p&gt;

&lt;p&gt;Compute APIs are much closer to the metal, exposing the underlying power of
the GPU without the intervening machinery and bugs of the OpenGL abstraction.
The API surface of these compute APIs are much smaller, which should mean
simpler and less buggy drivers. In addition the compute APIs are focused in
part on scientific applications, so the results from using compute APIs should
be much more repeatable. At the very least using compute APIs we are &lt;a href=&quot;https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/log.html&quot;&gt;in
control of what performance/accuracy tradeoff to make&lt;/a&gt;. Compute APIs are also
becoming more widely available, with every next generation API (Vulkan, DX12,
and Metal) supporting a compute component.&lt;/p&gt;

&lt;p&gt;One of the more surprising things I learned recently was exactly how sloppy
OpenGL could be. For example, from the &lt;a href=&quot;https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/log.html&quot;&gt;documentation for the OpenCL log
function&lt;/a&gt;,
you can choose between the native hardware accelerated version
of log, or use a log function that will return accurate results.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;native_log computes natural logarithm over an implementation-defined range. &lt;strong&gt;The maximum error is implementation-defined&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think it’s time for me to find an OpenCL library for &lt;a href=&quot;https://golang.org&quot;&gt;Go&lt;/a&gt; and
start exploring &lt;a href=&quot;https://cloud.google.com/gpu/&quot;&gt;GPU’s on Google Compute Engine&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">This article from Technology Review, How AI Can Keep Accelerating After Moore’s Law is a good follow-on from a previous article Moore’s Law Is Dead. Now What?.</summary></entry><entry><title type="html">North Carolina Urbanization and Rural Flight</title><link href="https://bitworking.org/news/2017/06/north-carolina-urbanization" rel="alternate" type="text/html" title="North Carolina Urbanization and Rural Flight" /><published>2017-06-18T00:00:00-04:00</published><updated>2017-06-18T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/06/north-carolina-urbanization</id><content type="html" xml:base="https://bitworking.org/news/2017/06/north-carolina-urbanization">&lt;p&gt;
  The rural areas of North Carolina are emptying out.
&lt;/p&gt;
&lt;style&gt;
  .tooltip {
    position: absolute;
    width: 200px;
    height: 28px;
    pointer-events: none;
  }

  text {
    font-size: 15px;
  }
&lt;/style&gt;

&lt;div id=plot&gt;&lt;/div&gt;

&lt;p style=&quot;text-align: center; font-size: 90%;&quot;&gt;
  &lt;a href=&quot;http://www.indexmundi.com/facts/united-states/quick-facts/north-carolina/population-growth#table&quot;&gt;
 North Carolina County Population vs Count Population Growth Rate (2010 -
 2014).&lt;/a&gt;&lt;br&gt;
 Click on the graph to toggle between population density and county
 population.
&lt;/p&gt;

&lt;p&gt;
  North Carolina is not immune to &lt;a
    href=&quot;https://en.wikipedia.org/wiki/Rural_flight&quot;&gt;Rural Flight&lt;/a&gt;, nor is
  it a special victim, as the phenomenon is happening world wide.
  Countrysides around the world are emptying out.
&lt;/p&gt;

&lt;iframe style=&quot;margin: 1em 2em;&quot; width=&quot;560&quot; height=&quot;315&quot;
  src=&quot;https://www.youtube.com/embed/B67LTsGENPQ&quot; frameborder=&quot;0&quot;
  allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
  It's important to keep these broader patterns in mind, first so you don't
  go &lt;a
    href=&quot;http://www.roanoke-chowannewsherald.com/2015/12/08/woodland-rejects-solar-farm/&quot;&gt;
    blaming random local events that look like correlation&lt;/a&gt;:
&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;
    Mary Hobbs has been living in Woodland for 50 years and said she has
    watched it slowly becoming a ghost town with no job opportunities for
    young people.
  &lt;/p&gt;
  &lt;p&gt;
    She said her home is surrounded by solar farms and is no longer worth its
    value because of those facilities.
  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And from the same article:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;
    Bobby Mann said he watched communities dry up when I-95 came along and
    warned that would happen to Woodland because of the solar farms.
  &lt;/p&gt;
  &lt;p&gt;
    “You’re killing your town,” he said. “All the young people are going to
    move out.”
  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
  But also so that when trying to &lt;a
    href=&quot;http://www.ncruralcenter.org/about-us/news/756-ruralurban-coalitions-highlighted-during-election-season&quot;&gt;formulate
    policy&lt;/a&gt; we temper trying to stop rural flight, which is probably
  impossible, with programs to help with relocation and the humane winding down of rural towns,
  because the &lt;a href=&quot;http://www.radiolab.org/story/seneca-nebraska/&quot;&gt;alternatives are
    pretty grim&lt;/a&gt;. And yes, let me state explicitly what I'm implying
  above, which is that people might have to move. Just like companies are not
  owed a business model, people aren't owed the job of their choice brought
  to their doorstop. But what should also be acknowledged is that moving
  for the poor is incredibly difficult and that any solutions proposed should
  address that gap.
&lt;/p&gt;

&lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt;
&lt;script&gt;
(function () {
  var margin = {top: 20, right: 20, bottom: 60, left: 60},
    width = 640 - margin.left - margin.right,
    height = 480 - margin.top - margin.bottom;

  var xlabels = [&quot;Density (people/mi^2)&quot;, &quot;Population per County (100K)&quot;];

  var x = d3.scalePow().exponent(1/10).range([0, width]);
  var y = d3.scaleLinear().range([height, 0]);

  var svg = d3.select(&quot;#plot&quot;).append(&quot;svg&quot;)
    .attr(&quot;width&quot;, width + margin.left + margin.right)
    .attr(&quot;height&quot;, height + margin.top + margin.bottom)
    .append(&quot;g&quot;)
    .attr(&quot;transform&quot;,
      &quot;translate(&quot; + margin.left + &quot;,&quot; + margin.top + &quot;)&quot;);

  var tooltip = d3.select(&quot;#plot&quot;).append(&quot;div&quot;)
    .attr(&quot;class&quot;, &quot;tooltip&quot;)
    .style(&quot;opacity&quot;, 0);

  var line = svg.append('line')
    .attr('id', 'fit')
    .attr('stroke-width', '2')
    .attr('stroke', 'grey');

  var data = [
    // Name, % change, population, size
    [&quot;Alamance&quot;,3,155792, 435],
    [&quot;Alexander&quot;,0.5,37392, 263],
    [&quot;Alleghany&quot;,-2.5,10879, 236],
    [&quot;Anson&quot;,-4.4,25765, 537],
    [&quot;Ashe&quot;,-0.6,27126, 427],
    [&quot;Avery&quot;,-0.1,17773, 247],
    [&quot;Beaufort&quot;,-0.4,47585, 959],
    [&quot;Bertie&quot;,-5.6,20106, 741],
    [&quot;Bladen&quot;,-1.5,34657, 887],
    [&quot;Brunswick&quot;,10.6,118836, 860],
    [&quot;Buncombe&quot;,5.1,250539, 660],
    [&quot;Burke&quot;,-1.6,89486, 515],
    [&quot;Cabarrus&quot;,7.8,192103, 365],
    [&quot;Caldwell&quot;,-1.9,81484, 474],
    [&quot;Camden&quot;,3.5,10331, 306],
    [&quot;Carteret&quot;,3.5,68811, 1341],
    [&quot;Caswell&quot;,-2.7,23082, 428],
    [&quot;Catawba&quot;,0.1,154534, 414],
    [&quot;Chatham&quot;,8.2,68698, 709],
    [&quot;Cherokee&quot;,-1.1,27141, 497],
    [&quot;Chowan&quot;,-1.5,14572, 233],
    [&quot;Clay&quot;,-0.1,10581, 221],
    [&quot;Cleveland&quot;,-1,97076,469 ],
    [&quot;Columbus&quot;,-2,56953, 954],
    [&quot;Craven&quot;,1,104510, 774],
    [&quot;Cumberland&quot;,2.2,326328, 658],
    [&quot;Currituck&quot;,6.1,24976, 526],
    [&quot;Dare&quot;,3.5,35104, 1562],
    [&quot;Davidson&quot;,0.7,164072, 567],
    [&quot;Davie&quot;,0.5,41434, 267],
    [&quot;Duplin&quot;,2.4,59882, 819],
    [&quot;Durham&quot;,9.1,294460, 298],
    [&quot;Edgecombe&quot;,-2.9,54933, 507],
    [&quot;Forsyth&quot;,4.2,365298, 413],
    [&quot;Franklin&quot;,3.7,62860, 495],
    [&quot;Gaston&quot;,2.4,211127, 364],
    [&quot;Gates&quot;,-5.1,11567, 346],
    [&quot;Graham&quot;,-2.4,8644, 302],
    [&quot;Granville&quot;,1.7,58500, 537],
    [&quot;Greene&quot;,-1.3,21093, 266],
    [&quot;Guilford&quot;,4.9,512119, 658],
    [&quot;Halifax&quot;,-3.1,52970, 731],
    [&quot;Harnett&quot;,10.5,126666, 601],
    [&quot;Haywood&quot;,0.7,59471, 555],
    [&quot;Henderson&quot;,4.1,111149, 375],
    [&quot;Hertford&quot;,-1.4,24308, 360],
    [&quot;Hoke&quot;,9.9,51611, 392],
    [&quot;Hyde&quot;,-2.3,5676, 1424],
    [&quot;Iredell&quot;,4.5,166675, 597],
    [&quot;Jackson&quot;,1.8,40981, 494],
    [&quot;Johnston&quot;,7.4,181423, 796],
    [&quot;Jones&quot;,-0.8,10076, 473],
    [&quot;Lee&quot;,3.1,59662, 259],
    [&quot;Lenoir&quot;,-1.7,58485, 402],
    [&quot;Lincoln&quot;,2,79829, 307],
    [&quot;Macon&quot;,-0.1,33875, 519],
    [&quot;Madison&quot;,1.8,21157, 452],
    [&quot;Martin&quot;,-4.3,23454, 461],
    [&quot;McDowell&quot;,-0.1,44965, 446],
    [&quot;Mecklenburg&quot;,10.1,1012539, 546],
    [&quot;Mitchell&quot;,-1.7,15311, 222],
    [&quot;Montgomery&quot;,-1.4,27395, 502],
    [&quot;Moore&quot;,5.5,93077, 706],
    [&quot;Nash&quot;,-1.5,94357, 543],
    [&quot;New Hanover&quot;,6.7,216298, 328],
    [&quot;Northampton&quot;,-7.4,20463, 551],
    [&quot;Onslow&quot;,5.5,187589, 909],
    [&quot;Orange&quot;,5,140420, 401],
    [&quot;Pamlico&quot;,-1.5,12948, 566],
    [&quot;Pasquotank&quot;,-2.1,39787, 289],
    [&quot;Pender&quot;,7.8,56250, 933],
    [&quot;Perquimans&quot;,0.1,13466, 329],
    [&quot;Person&quot;,-0.8,39132, 404],
    [&quot;Pitt&quot;,4.3,175354, 655],
    [&quot;Polk&quot;,-0.7,20357, 239],
    [&quot;Randolph&quot;,0.7,142778, 790],
    [&quot;Richmond&quot;,-1.9,45733, 480],
    [&quot;Robeson&quot;,0.4,134760, 951],
    [&quot;Rockingham&quot;,-2.1,91696, 572],
    [&quot;Rowan&quot;,0.1,138630, 524],
    [&quot;Rutherford&quot;,-1.8,66600, 566],
    [&quot;Sampson&quot;,1,64050, 947],
    [&quot;Scotland&quot;,-1.6,35576, 321],
    [&quot;Stanly&quot;,0,60600, 404],
    [&quot;Stokes&quot;,-2.1,46419, 456],
    [&quot;Surry&quot;,-1,72968, 538],
    [&quot;Swain&quot;,2.1,14274, 541],
    [&quot;Transylvania&quot;,-0.1,33045, 381],
    [&quot;Tyrrell&quot;,-6.6,4115, 600],
    [&quot;Union&quot;,8.6,218568, 640],
    [&quot;Vance&quot;,-1.8,44614, 270],
    [&quot;Wake&quot;,10.8,998691, 857],
    [&quot;Warren&quot;,-3.5,20231, 444],
    [&quot;Washington&quot;,-4.9,12570, 424],
    [&quot;Watauga&quot;,2.9,52560, 313],
    [&quot;Wayne&quot;,1.5,124456, 557],
    [&quot;Wilkes&quot;,-0.7,68838, 760],
    [&quot;Wilson&quot;,0.2,81401, 374],
    [&quot;Yadkin&quot;,-1.6,37792, 337],
    [&quot;yancey&quot;,-1.1,17614, 313]
  ]

  var mode = 0;

  function calcDerivedColumn() {
    if (mode ==0) {
      data.forEach(function(d) {
        d[4] = d[2]/d[3];
      });
    } else {
      data.forEach(function(d) {
        d[4] = d[2]/100000;
      });
    }
  }

  calcDerivedColumn();

  svg.append('text')
    .attr('transform', 'rotate(-90)')
    .attr('dx', '-20em')
    .attr('dy', '-2em')
    .text('County Population Change (%)');

  svg.append('text')
    .attr('transform', `translate(${width/2},${height + 2*margin.bottom/3})`)
    .attr('dx', '-8em')
    .attr('id', 'xlabel')
    .text(xlabels[mode]);

  svg.append('text')
    .attr('id', 'r')
    .attr('dx', '25em')
    .attr('dy', '20em')
    .text('r=');

  x.domain(d3.extent(data, function(d) { return d[4]; }));
  y.domain(d3.extent(data, function(d) { return d[1]; }));

  function plotLine(t) {
    var xSeries=[];
    var ySeries=[];
    data.forEach(function(d) {
      xSeries.push(Math.log10(d[4]));
      ySeries.push(d[1]);
    });

    var ls = leastSquares(xSeries, ySeries);
    xSeries.sort(function(a, b) {
      return a - b;
    });
    var x1= xSeries[0];
    var y1= ls.m * x1 + ls.b;
    var x2= xSeries[xSeries.length-1];
    var y2= ls.m * x2 + ls.b;
    x1 = Math.pow(10, x1);
    x2 = Math.pow(10, x2);
    svg.selectAll('#fit').transition(t)
      .attr('x1', x(x1))
      .attr('y1', y(y1))
      .attr('x2', x(x2))
      .attr('y2', y(y2));
    svg.selectAll('#r')
      .text('r=' + ls.r.toPrecision(2));
  }
  plotLine(d3.transition());

  // Enter the scatterplot.
  svg.selectAll(&quot;circle&quot;)
    .data(data)
    .enter().append(&quot;circle&quot;)
    .attr(&quot;r&quot;, 5)
    .attr(&quot;cx&quot;, function(d) { return x(d[4]); })
    .attr(&quot;cy&quot;, function(d) { return y(d[1]); })
    .attr(&quot;fill&quot;, function(d) { return d[1] &lt; 0 ? &quot;#ff3333&quot; : &quot;#009999&quot;; })
    .attr(&quot;title&quot;, function(d) { return d[0]; })
    .on(&quot;mouseover&quot;, function(d) {
      tooltip.transition()
        .duration(200)
        .style(&quot;opacity&quot;, .9);
      tooltip.html(d[0])
        .style(&quot;left&quot;, (d3.event.pageX + 5) + &quot;px&quot;)
        .style(&quot;top&quot;, (d3.event.pageY - 28) + &quot;px&quot;);
    })
    .on(&quot;mouseout&quot;, function(d) {
      tooltip.transition()
        .duration(500)
        .style(&quot;opacity&quot;, 0);
    });
  d3.selectAll(&quot;svg&quot;)
    .on(&quot;click&quot;, function(d) {
      toggle();
    });

  // Add the X Axis
  svg.append(&quot;g&quot;)
    .attr(&quot;transform&quot;, &quot;translate(0,&quot; + height + &quot;)&quot;)
    .attr(&quot;id&quot;, &quot;xaxis&quot;)
    .call(d3.axisBottom(x));

  // Add the Y Axis
  svg.append(&quot;g&quot;)
    .call(d3.axisLeft(y));

  function toggle() {
    mode = (mode+1)%2;
    var t = d3.transition()
      .duration(750);

    svg.selectAll('#xlabel')
      .text(xlabels[mode]);

    calcDerivedColumn();
    x.domain(d3.extent(data, function(d) { return d[4]; }));
    y.domain(d3.extent(data, function(d) { return d[1]; }));
    plotLine(t);
    svg.selectAll(&quot;circle&quot;)
      .data(data, function(d) { return d; })
      .transition(t)
      .attr(&quot;cx&quot;, function(d) { return x(d[4]); })

    d3.selectAll(&quot;#xaxis&quot;)
      .call(d3.axisBottom(x));
  }

  function leastSquares(xSeries, ySeries) {
    var reduceSumFunc = function(prev, cur) { return prev + cur; };

    var xBar = xSeries.reduce(reduceSumFunc) * 1.0 / xSeries.length;
    var yBar = ySeries.reduce(reduceSumFunc) * 1.0 / ySeries.length;

    var ssXX = xSeries.map(function(d) { return (d-xBar)*(d-xBar); })
      .reduce(reduceSumFunc);

    var ssYY = ySeries.map(function(d) { return (d-yBar)*(d-yBar); })
      .reduce(reduceSumFunc);

    var ssXY = xSeries.map(function(d, i) { return (d - xBar) * (ySeries[i] - yBar); })
      .reduce(reduceSumFunc);

    var slope = ssXY / ssXX;
    var intercept = yBar - (xBar * slope);
    var r = ssXY / (Math.sqrt(ssXX) * Math.sqrt(ssYY));

    return {m: slope, b: intercept, r: r};
  }

})();
&lt;/script&gt;</content><author><name></name></author><summary type="html">The rural areas of North Carolina are emptying out. .tooltip { position: absolute; width: 200px; height: 28px; pointer-events: none; }</summary></entry><entry><title type="html">Noisy Frogs</title><link href="https://bitworking.org/news/2017/06/noisy-frogs" rel="alternate" type="text/html" title="Noisy Frogs" /><published>2017-06-15T00:00:00-04:00</published><updated>2017-06-15T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/06/noisy-frogs</id><content type="html" xml:base="https://bitworking.org/news/2017/06/noisy-frogs">&lt;p&gt;Why yes, the frogs in the pond across the road are rather loud.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/noisy_frogs_small.png&quot; alt=&quot;Graph showing a peak noise level of 72 dB.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BTW,
&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.google.android.apps.forscience.whistlepunk&amp;amp;hl=en&quot;&gt;Google Science Journal&lt;/a&gt;
is awesome.&lt;/p&gt;</content><author><name></name></author><summary type="html">Why yes, the frogs in the pond across the road are rather loud.</summary></entry><entry><title type="html">Moving to Jekyll</title><link href="https://bitworking.org/news/2017/06/moving-to-jekyll" rel="alternate" type="text/html" title="Moving to Jekyll" /><published>2017-06-15T00:00:00-04:00</published><updated>2017-06-15T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/06/moving-to-jekyll</id><content type="html" xml:base="https://bitworking.org/news/2017/06/moving-to-jekyll">&lt;p&gt;I am in the process of moving this blog over to
&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;, while at the same time admitting that I’m
never going to finish writing my own blogging software, and that I really
should concentrate on the writing, and not the underlying software.&lt;/p&gt;

&lt;p&gt;This is also an admission that for a while there may be general brokenness
such as broken links and some horribly formatted posts.&lt;/p&gt;

&lt;p&gt;Also, I will be turning on comments, which is a longer post in itself, but
let’s just say that after years of watching abuse and generally uncivil
behavior on all the social networks I’ve decided to revert to old technology
from a simpler time, where I get to have absolute control over what appears
next to my writing. Call me old fashioned.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: And comments are now enabled, the &lt;a href=&quot;https://github.com/jekyll/minima&quot;&gt;Jekyll Minima
theme&lt;/a&gt; and &lt;a href=&quot;https://disqus.com/&quot;&gt;Disqus&lt;/a&gt;
made that way too easy.&lt;/p&gt;</content><author><name></name></author><summary type="html">I am in the process of moving this blog over to Jekyll, while at the same time admitting that I’m never going to finish writing my own blogging software, and that I really should concentrate on the writing, and not the underlying software.</summary></entry><entry><title type="html">Tech Driven Deflation</title><link href="https://bitworking.org/news/2017/04/tech-driven-deflation" rel="alternate" type="text/html" title="Tech Driven Deflation" /><published>2017-04-19T00:00:00-04:00</published><updated>2017-04-19T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/04/tech-driven-deflation</id><content type="html" xml:base="https://bitworking.org/news/2017/04/tech-driven-deflation">&lt;p&gt;
    The article &lt;a href=&quot;https://singularityhub.com/2017/04/14/will-tech-driven-deflation-export-japans-economic-woes-to-the-world/&quot;&gt;Will Tech-Driven Deflation Export Japan’s Economic Woes to the World?&lt;/a&gt;
    reminded me of this video, &amp;#34;Evolution of the Desk&amp;#34;:
  &lt;/p&gt;
  &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/uGI00HV7Cfw?rel=0&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
  &lt;p&gt;
    The origin for the above video is &lt;a href=&quot;http://bestreviews.com/electronics#evolution-of-the-desk&quot;&gt;http://bestreviews.com/electronics#evolution-of-the-desk&lt;/a&gt;.
  &lt;/p&gt;

  &lt;p&gt;
    Each time an object gets digitized that&amp;#39;s one less object to
    manufacture, one less object to ship, one less object consuming
    raw materials. It&amp;#39;s actually more surprising that this hasn&amp;#39;t had
    an even larger impact on the U.S. economy.
  &lt;/p&gt;

  &lt;p&gt;
    &lt;b&gt;Update:&lt;/b&gt; A &lt;a href=&quot;https://www.brookings.edu/wp-content/uploads/2016/08/varian.pdf&quot;&gt;great
      slide deck from Hal Varian&lt;/a&gt; covers the same ground with a slightly different take, pointing
    out that much of this progress not only doesn't increase GDP, it actually
    reduces it, which is a problem of using GDP as a metric.
  &lt;/p&gt;</content><author><name></name></author><summary type="html">The article Will Tech-Driven Deflation Export Japan’s Economic Woes to the World? reminded me of this video, &amp;#34;Evolution of the Desk&amp;#34;: The origin for the above video is http://bestreviews.com/electronics#evolution-of-the-desk.</summary></entry><entry><title type="html">Prometheus vs InfluxDB</title><link href="https://bitworking.org/news/2017/03/prometheus" rel="alternate" type="text/html" title="Prometheus vs InfluxDB" /><published>2017-03-18T00:00:00-04:00</published><updated>2017-03-18T00:00:00-04:00</updated><id>https://bitworking.org/news/2017/03/prometheus</id><content type="html" xml:base="https://bitworking.org/news/2017/03/prometheus">&lt;p&gt;
    We just finished migrating all of our monitoring from &lt;a href=&quot;https://www.influxdata.com/&quot;&gt;InfluxDB&lt;/a&gt; to &lt;a href=&quot;https://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt; and I thought I&amp;#39;d write up
    our reasons for the change. Please note that these are my own personal
    observations and relate to a specific project, these issue may not apply
    to you and you should evaluate each product for your own uses.
  &lt;/p&gt;
  &lt;p&gt;
    &lt;b&gt;Update:&lt;/b&gt; To clarify, the versions of InfluxDB and Prometheus that I
    am talking about are InfluxDB 1.1.1 and Prometheus 1.5.2.
  &lt;/p&gt;

  &lt;h2&gt;Push vs Pull&lt;/h2&gt;
  &lt;dl&gt;
    &lt;dt&gt;InfluxDB&lt;/dt&gt;
    &lt;dd&gt;
      InfluxDB is a push based system, i.e. your running application needs
      to actively push data into the monitoring system.
    &lt;/dd&gt;
    &lt;dt&gt;Prometheus&lt;/dt&gt;
    &lt;dd&gt;
      Prometheus is a pull based system, the Prometheus server fetches the
      metrics values from the running application periodically.
    &lt;/dd&gt;
  &lt;/dl&gt;
  &lt;p&gt;
    With centralized control of how polling is done with Prometheus I can
    switch from polling every minute to every 10 seconds just by adjusting the
    configuration of the Prometheus server. With InfluxDB I would have to
    redeploy every application with a change to how often they should push
    metrics. In addition the Prometheus pull method allows Prometheus to
    create and offer a synthetic &amp;#34;UP&amp;#34; metric that monitors whether an
    application is up and running.
    For short lived applications Prometheus has a &lt;a href=&quot;https://github.com/prometheus/pushgateway&quot;&gt;push gateway&lt;/a&gt;.
  &lt;/p&gt;

  &lt;h2&gt;Datastore&lt;/h2&gt;
  &lt;dl&gt;
    &lt;dt&gt;InfluxDB&lt;/dt&gt;
    &lt;dd&gt;
      InfluxDB has a monolithic database for both metric values and indices.
    &lt;/dd&gt;
    &lt;dt&gt;Prometheus&lt;/dt&gt;
    &lt;dd&gt;
      Prometheus uses LevelDB for indices, but each metric is stored in its
      own file.
    &lt;/dd&gt;
  &lt;/dl&gt;
  &lt;p&gt;
    Both use key/value datastores, but how they use them is very different
    and it affects the performance of the products. InfluxDB was
    slower and took up substantially more disk space than Prometheus for the
    same exact set of metics. Just starting up InfluxDB and sending a small
    number of metrics to it caused the datastore to grow to 1GB, and then
    grow rapidly from there to 100&amp;#39;s of GB for our full set of metrics,
    while Prometheus has yet to crack 10GB with all of our metrics.
    And let&amp;#39;s not even go into the number of times InfluxDB lost all of our
    data, either from a crash or from a failed attempt to upgrade the
    version of InfluxDB that we were running.
  &lt;/p&gt;
  &lt;p&gt;
    &lt;b&gt;Update:&lt;/b&gt; I was also reminded there's another datastore related issue
    with startup time, while Prometheus starts in a matter of seconds,
    InfluxDB would regularly take 5 minutes to restart while it either
    validated or rebuilt its indices and would not collect data during the
    entire process.
  &lt;/p&gt;

  &lt;h2&gt;CPU&lt;/h2&gt;
  &lt;p&gt;
    Probably closely related to the datastore efficiency, InfluxDB was coming
    close to maxing out the server it was running on, while Prometheus running
    on an identical instance peaks at maybe 0.2 load.
  &lt;/p&gt;

  &lt;h2&gt;Query Language&lt;/h2&gt;
  &lt;dl&gt;
    &lt;dt&gt;InfluxDB&lt;/dt&gt;
    &lt;dd&gt;
      InfluxDB uses a variant of SQL.
    &lt;/dd&gt;
    &lt;dt&gt;Prometheus&lt;/dt&gt;
    &lt;dd&gt;
      Uses a substantially simpler and more direct querying model.
    &lt;/dd&gt;
  &lt;/dl&gt;
  &lt;p&gt;
    What would you rather type?
  &lt;/p&gt;
  &lt;pre&gt;&lt;code&gt;SELECT * FROM &amp;#34;cpu_load_short&amp;#34; WHERE &amp;#34;value&amp;#34; &amp;gt; 0.9&lt;/code&gt;&lt;/pre&gt;
  &lt;p&gt;or&lt;/p&gt;
  &lt;pre&gt;&lt;code&gt;cpu_load_short &amp;gt; 0.9&lt;/code&gt;&lt;/pre&gt;

  &lt;h2&gt;Configuration&lt;/h2&gt;
  &lt;dl&gt;
    &lt;dt&gt;InfluxDB&lt;/dt&gt;
    &lt;dd&gt;
      Configuration is done through a mix of config files and SQL
      commands sent to the server.
    &lt;/dd&gt;
    &lt;dt&gt;Prometheus&lt;/dt&gt;
    &lt;dd&gt;
      Text files.
    &lt;/dd&gt;
  &lt;/dl&gt;
  &lt;p&gt;
    Prometheus config is simply YAML files, and the entire config is done via
    files. With InfluxDB you have to worry that some of the config, for
    example, creating the named database that metrics are to be stored in,
    actually gets done. Additionally Prometheus just picks more reasonable
    defaults, for example, it defaults to only storing data for 15 days, while
    InfluxDB defaults to storing all data forever, and if you don&amp;#39;t want to
    store all data forever you need to construct an SQL command to send to the
    server to control how data is retained.
  &lt;/p&gt;</content><author><name></name></author><summary type="html">We just finished migrating all of our monitoring from InfluxDB to Prometheus and I thought I&amp;#39;d write up our reasons for the change. Please note that these are my own personal observations and relate to a specific project, these issue may not apply to you and you should evaluate each product for your own uses. Update: To clarify, the versions of InfluxDB and Prometheus that I am talking about are InfluxDB 1.1.1 and Prometheus 1.5.2.</summary></entry><entry><title type="html">Geometric Algebra applied to Physics</title><link href="https://bitworking.org/news/ga/physics.html" rel="alternate" type="text/html" title="Geometric Algebra applied to Physics" /><published>2017-01-01T00:00:00-05:00</published><updated>2017-01-01T00:00:00-05:00</updated><id>https://bitworking.org/news/ga/physics</id><content type="html" xml:base="https://bitworking.org/news/ga/physics.html">&lt;style type=&quot;text/css&quot; media=&quot;screen&quot;&gt;
    img {
      vertical-align: baseline;
    }

    th {
      background: #fff;
    }
  &lt;/style&gt;
  &lt;script src=&quot;/js/ga2d.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;/js/draw_ga2d.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
  &lt;p&gt;
    Geometric Algebra can be applied to Physics, and many of the introductions
    to GA online cover this, but they immediately jump to electromagnetic
    fields or quantum mechanics, which is unfortunate since GA can also
    greatly simplify 2D kinematics. One such example is uniform circular
    motion.
  &lt;/p&gt;

  &lt;p class=aside&gt;
    You should be familiar with all the concepts presented in &lt;a
      href=&quot;https://bitworking.org/news/ga/2d&quot;&gt;An Introduction to Geometric
      Algebra over R^2&lt;/a&gt; before proceeding.
  &lt;/p&gt;

  &lt;p&gt;
    If we have a vector &lt;b&gt;p&lt;/b&gt; that moves at a constant rate of &amp;omega;
    rad/s and has a starting position &lt;b&gt;p&lt;sub&gt;0&lt;/sub&gt;&lt;/b&gt;, then we can
    describe the vector &lt;b&gt;p&lt;/b&gt; very easily:
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;$$\boldsymbol{p} = \boldsymbol{p_0} e^{\omega t \boldsymbol{I}}$$&lt;/dd&gt;
  &lt;/dl&gt;

  &lt;button id=rotor_toggle&gt;Start/Stop&lt;/button&gt;
  &lt;canvas id=rotor width=300 height=300&gt;&lt;/canvas&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var button = document.getElementById('rotor_toggle');
      var running = false;
      var omega = 0.5;
      var start = Date.now();
      var p0 = ga2d.vec(0, -1);
      var f = new draw_ga2d.Frame(document.getElementById('rotor'));
      var step = function() {
        var rotor = ga2d.e(omega * (Date.now() - start)/1000);
        var p = ga2d.mul(p0, rotor);
        f.clear();
        f.expandTo([0, 1, 1, 0]);
        f.expandTo([0, -1, -1, 0]);
        f.vec(p, &quot;p&quot;);
        f.draw();
        if (running) {
          window.requestAnimationFrame(step);
        }
      };

      button.addEventListener('click', function() {
        running = !running;
        if (running) {
          start = Date.now();
          window.requestAnimationFrame(step);
        }
      });
      step();
    })();
  &lt;/script&gt;

  &lt;p&gt;
    Let's figure out what the derivative of a Rotor looks like, by
    first recalling its definition:
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;$$ e^{\theta \boldsymbol{I}} := \cos(\theta) + \sin(\theta)\boldsymbol{I}$$&lt;/dd&gt;
  &lt;/dl&gt;
  &lt;p&gt;
    We take the derivative with respect to &amp;theta;:
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;
      $$
        \begin{align*}
          \frac{d}{d \theta} e^{\theta \boldsymbol{I}} &amp;=  \frac{d}{d \theta} (\cos(\theta) + \sin(\theta)\boldsymbol{I}) \\
            &amp;=  -\sin(\theta) + \cos(\theta)\boldsymbol{I} \\
        \end{align*}
      $$
    &lt;/dd&gt;
  &lt;/dl&gt;

  &lt;p&gt;
    At this point observe that &lt;em&gt;cos&lt;/em&gt; and &lt;em&gt;sin&lt;/em&gt; just changed
    places, along with a sign change, but we know of another operation that does
    the same thing, which is multiplication by &lt;b&gt;I&lt;/b&gt;, so we get:
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;
      $$
        \begin{align*}
          \frac{d}{d \theta} e^{\theta \boldsymbol{I}} &amp;= \frac{d}{d \theta} (\cos(\theta) + \sin(\theta)\boldsymbol{I}) \\
            &amp;= -\sin(\theta) + \cos(\theta)\boldsymbol{I}          \\
            &amp;= \boldsymbol{I} (\cos(\theta) + \sin(\theta)\boldsymbol{I})  \\
            &amp;= \boldsymbol{I} e^{\theta \boldsymbol{I}}                    \\
        \end{align*}
      $$
    &lt;/dd&gt;
  &lt;/dl&gt;

  &lt;p&gt;
    Not only does the derivative have a nice neat expression, we can read off
    from the formula what is happening, which is that the derivative is a vector
    that is rotated 90 degrees from the original vector. Also note that
    normally the geometric product ins't commutative, but in this case both
    parts are rotors, so the order doesn't matter.
  &lt;/p&gt;

  &lt;p&gt;
    We can go through the same process to show what happens if &amp;theta; has
    a constant multiplier &lt;em&gt;k&lt;/em&gt;:
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;
      $$
        \begin{align*}
          \frac{d}{d \theta} e^{k \theta \boldsymbol{I}} &amp;= \frac{d}{d \theta} (\cos(k \theta) + \sin(k \theta)\boldsymbol{I}) \\
            &amp;= k \boldsymbol{I} e^{k \theta \boldsymbol{I}} \\
        \end{align*}
      $$
    &lt;/dd&gt;
  &lt;/dl&gt;

  &lt;p&gt;
    With our new derivative in hand we can now find the velocity vector
    for our position vector &lt;b&gt;p&lt;/b&gt;, since velocity is just the derivative
    of position with respect to time.
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;
      $$
        \begin{align*}
        \boldsymbol{v}  &amp;= \frac{d}{dt} \boldsymbol{p} \\
                &amp;= \frac{d}{dt} \boldsymbol{p_0} e^{\omega t \boldsymbol{I}} \\
                &amp;= \boldsymbol{p_0} \omega \boldsymbol{I}  e^{\omega t \boldsymbol{I}} \\
                &amp;= \omega \boldsymbol{p_0} \boldsymbol{I} e^{\omega t \boldsymbol{I}} \\
        \end{align*}
      $$
    &lt;/dd&gt;
  &lt;/dl&gt;

  &lt;p&gt;
    Again, because we using Geometric Algebra, we can read off
    what is going on geometrically from the formula, that is,
    the derivative is a vector orthogonal to the position vector
    that is scaled by &amp;omega;.
  &lt;/p&gt;

  &lt;button id=velocity_toggle&gt;Start/Stop&lt;/button&gt;
  &lt;canvas id=velocity width=300 height=300&gt;&lt;/canvas&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var button = document.getElementById('velocity_toggle');
      var running = false;
      var omega = 0.5;
      var omegaScalar = ga2d.scalar(omega);
      var I = [0, 0, 0, 1];
      var start = Date.now();
      var p0 = ga2d.vec(0, -1);
      var f = new draw_ga2d.Frame(document.getElementById('velocity'));
      var step = function() {
        var rotor = ga2d.e(omega * (Date.now() - start)/1000);
        var p = ga2d.mul(p0, rotor);
        var v = ga2d.mul(omegaScalar, ga2d.mul(p0, ga2d.mul(I, rotor)));
        f.clear();
        f.expandTo([0, 1, 1, 0]);
        f.expandTo([0, -1, -1, 0]);
        f.vec(p, &quot;p&quot;);
        f.vecFrom(v, p, &quot;v&quot;);
        f.draw();
        if (running) {
          window.requestAnimationFrame(step);
        }
      };

      button.addEventListener('click', function() {
        running = !running;
        if (running) {
          start = Date.now();
          window.requestAnimationFrame(step);
        }
      });
      step();
    })();
  &lt;/script&gt;

  &lt;p&gt;
    Note that we've drawn the vector as starting from the position,
    but that's not required.
  &lt;/p&gt;

  &lt;button id=sep_velocity_toggle&gt;Start/Stop&lt;/button&gt;
  &lt;canvas id=sep_velocity width=300 height=300&gt;&lt;/canvas&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var button = document.getElementById('sep_velocity_toggle');
      var running = false;
      var omega = 0.5;
      var omegaScalar = ga2d.scalar(omega);
      var I = [0, 0, 0, 1];
      var start = Date.now();
      var p0 = ga2d.vec(0, -1);
      var f = new draw_ga2d.Frame(document.getElementById('sep_velocity'));
      var step = function() {
        var rotor = ga2d.e(omega * (Date.now() - start)/1000);
        var p = ga2d.mul(p0, rotor);
        var v = ga2d.mul(omegaScalar, ga2d.mul(p0, ga2d.mul(I, rotor)));
        f.clear();
        f.expandTo([0, 1, 1, 0]);
        f.expandTo([0, -1, -1, 0]);
        f.vec(p, &quot;p&quot;);
        f.vec(v, &quot;v&quot;);
        f.draw();
        if (running) {
          window.requestAnimationFrame(step);
        }
      };

      button.addEventListener('click', function() {
        running = !running;
        if (running) {
          start = Date.now();
          window.requestAnimationFrame(step);
        }
      });
      step();
    })();
  &lt;/script&gt;

  &lt;p&gt;
    We get the acceleration vector in the same manner, by taking
    the derivative of the velocity vector with respect to time.
  &lt;/p&gt;

  &lt;dl&gt;
    &lt;dd&gt;
      $$
        \begin{align*}
        \boldsymbol{a}  &amp;= \frac{d}{dt} \boldsymbol{v}                                      \\
                &amp;= \frac{d}{dt} \omega \boldsymbol{p_0} \boldsymbol{I} e^{\omega t \boldsymbol{I}}  \\
                &amp;= \omega \boldsymbol{p_0} \boldsymbol{I} \omega \boldsymbol{I} e^{\omega t \boldsymbol{I}} \\
                &amp;= \omega^2 \boldsymbol{p_0} \boldsymbol{I} \boldsymbol{I} e^{\omega t \boldsymbol{I}}      \\
                &amp;= - \omega^2 \boldsymbol{p_0} e^{\omega t \boldsymbol{I}}
        \end{align*}
      $$
    &lt;/dd&gt;
  &lt;/dl&gt;

  &lt;p&gt;
    And again we can just read off from the formula what is going on
    geometrically, which is that we end up with a vector that is rotated
    180 degrees from the position vector, and scaled by &amp;omega;&lt;sup&gt;2&lt;/sup&gt;.
  &lt;/p&gt;

  &lt;button id=accel_toggle&gt;Start/Stop&lt;/button&gt;
  &lt;canvas id=accel width=300 height=300&gt;&lt;/canvas&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var button = document.getElementById('accel_toggle');
      var running = false;
      var omega = 0.5;
      var omegaScalar = ga2d.scalar(omega);
      var I = [0, 0, 0, 1];
      var start = Date.now();
      var p0 = ga2d.vec(0, -1);
      var f = new draw_ga2d.Frame(document.getElementById('accel'));
      var step = function() {
        var rotor = ga2d.e(omega * (Date.now() - start)/1000);
        var p = ga2d.mul(p0, rotor);
        var v = ga2d.mul(omegaScalar, ga2d.mul(p0, ga2d.mul(I, rotor)));
        var a = ga2d.mul(omegaScalar, ga2d.mul(v, I));
        f.clear();
        f.expandTo([0, 1, 1, 0]);
        f.expandTo([0, -1, -1, 0]);
        f.vec(p, &quot;p&quot;);
        f.vec(v, &quot;v&quot;);
        f.vec(a, &quot;a&quot;);
        f.draw();
        if (running) {
          window.requestAnimationFrame(step);
        }
      };

      button.addEventListener('click', function() {
        running = !running;
        if (running) {
          start = Date.now();
          window.requestAnimationFrame(step);
        }
      });
      step();
    })();
  &lt;/script&gt;

  &lt;p&gt;
    We can place the acceleration and velocity vectors as starting
    from the positition vector, and that looks like:
  &lt;/p&gt;

  &lt;button id=accel_from_toggle&gt;Start/Stop&lt;/button&gt;
  &lt;canvas id=accel_from width=300 height=300&gt;&lt;/canvas&gt;
  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;
    (function () {
      var button = document.getElementById('accel_from_toggle');
      var running = false;
      var omega = 0.5;
      var omegaScalar = ga2d.scalar(omega);
      var I = [0, 0, 0, 1];
      var start = Date.now();
      var p0 = ga2d.vec(0, -1);
      var f = new draw_ga2d.Frame(document.getElementById('accel_from'));
      var step = function() {
        var rotor = ga2d.e(omega * (Date.now() - start)/1000);
        var p = ga2d.mul(p0, rotor);
        var v = ga2d.mul(omegaScalar, ga2d.mul(p0, ga2d.mul(I, rotor)));
        var a = ga2d.mul(omegaScalar, ga2d.mul(v, I));
        f.clear();
        f.expandTo([0, 1, 1, 0]);
        f.expandTo([0, -1, -1, 0]);
        f.vecFrom(v, p, &quot;v&quot;);
        f.vecFrom(a, p, &quot;a&quot;);
        f.draw();
        if (running) {
          window.requestAnimationFrame(step);
        }
      };

      button.addEventListener('click', function() {
        running = !running;
        if (running) {
          start = Date.now();
          window.requestAnimationFrame(step);
        }
      });
      step();
    })();
  &lt;/script&gt;

  &lt;p&gt;
    Note how simple this was to derive and that the geometric interpretation
    could be read off of the resulting formulas. We didn't need to leave the
    2D plane, that is, all of these calculations took place in 𝔾&lt;sup&gt;2&lt;/sup&gt;.
    The more classical derivations for uniform circular motion rely on the
    cross-product which takes you out of ℝ&lt;sup&gt;2&lt;/sup&gt; into ℝ&lt;sup&gt;3&lt;/sup&gt; and
    which doesn't work in higher level dimensions.
  &lt;/p&gt;</content><author><name></name></author><summary type="html">img { vertical-align: baseline; }</summary></entry></feed>